#!/opt/common/CentOS_6-dev/python/python-2.7.10/bin/python

import argparse, os, sys, signal, subprocess, math, gzip, io
import cmo
import multiprocessing

def chunk(fastq, platform_unit, lines_per_chunk, num_pieces):
    logger = cmo.util.get_logger()
    output_prefix = os.path.basename(fastq).split(".", 1)[0] + "."
    if(platform_unit != None):
        exploded = output_prefix.split("_")
        exploded[0]=platform_unit
        output_prefix = "-".join(exploded)
    while lines_per_chunk % 4 != 0:
        lines_per_chunk +=1
    fh = io.BufferedReader(gzip.open(fastq, "rb"))
    output_file_count = 0
    output_file_lines = 0
    #these aren't relaly gz but trimgalore doesnt like files not named gz...great work trimgalore
    filename = output_prefix +  "chunk{:0>3d}".format(output_file_count) +  ".fastq.gz"
    logger.info("Opening %s and writing reads..." % (filename))
    ofh = gzip.open(filename, "wb", 1)
    lines = list()
    for line in os.popen("zcat " + fastq):
        lines.append(line)
        output_file_lines+=1
        if output_file_lines == lines_per_chunk:
            if(output_file_count < int(num_pieces)-1):
                output_file_lines=0
                ofh.write("".join(lines))
                ofh.close()
                lines = list()
                output_file_count +=1
                filename = output_prefix + "chunk{:0>3d}".format(output_file_count) +  ".fastq.gz"
                logger.info("Opening %s and writing reads..." % (filename))
                ofh = gzip.open(filename, "wb", 1)
    ofh.write("".join(lines))
    ofh.close()
    return True


if __name__ =='__main__':
    logger = cmo.util.get_logger()
    parser = argparse.ArgumentParser(description="split files into chunks based on filesize")
    parser.add_argument('-f1', "--fastq1", action='store', help="filename to split", required=True)
    parser.add_argument('-f2', "--fastq2", action='store', help="filename2 to split")
#    parser.add_argument('-s', "--sample", action='store', help="sample ID", required=True)
    parser.add_argument('-p', "--platform-unit", action='store', help="RG/PU ID", required=True)
    args = parser.parse_args()
    fastqs = [args.fastq1]
    if args.fastq2:
        fastqs.append(args.fastq2)
    filesize = os.path.getsize(fastqs[0])
    logger.info("Fastq1 Filesize: %sGB" % ("{:.2f}".format(float(filesize)/1000000000)))
    num_pieces = math.ceil(float(filesize)/350000000)
    logger.info("Splitting into %s pieces" % "{:.0f}".format(num_pieces))
    num_lines = sum(1 for line in os.popen("zcat " + fastqs[0]))
    lines_per_chunk = math.ceil(float(num_lines) / int(num_pieces))
    logger.info("%s lines per chunk" % str(lines_per_chunk))
    pool=multiprocessing.Pool(processes=2)
    for fastq in fastqs:
        result = pool.apply_async(chunk, args=(fastq, args.platform_unit, lines_per_chunk, num_pieces, ))
    pool.close()
    pool.join()

                


        




      
   


